# -*- coding: utf-8 -*-
"""diana.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F5uUG_L_-oWNPccg0D1oqPxXOAplHRYS

#UTILI
"""

!pip install -q ultralytics

import os
import cv2
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
from sklearn.model_selection import train_test_split
import albumentations as A

"""##vari path"""

from google.colab import drive
drive.mount('/content/drive')

rootim="/content/drive/MyDrive/dataset/"

model_path = "/content/drive/MyDrive/dataset/best.pt"

train_img="/content/drive/MyDrive/dataset/train/images"
val_img="/content/drive/MyDrive/dataset/valid/images"
test_img="/content/drive/MyDrive/dataset/test/images"

train_lbl="/content/drive/MyDrive/dataset/train/labels"
val_lbl="/content/drive/MyDrive/dataset/valid/labels"
test_lbl="/content/drive/MyDrive/dataset/test/labels"

data_yaml_path = "/content/drive/MyDrive/dataset/data.yaml"

"""# PREPARAZIONE DATI"""

# EDA and Data Preprocessing
def load_labels(label_path):
    label_files = os.listdir(label_path)
    data = []
    classes = set()
    for file in label_files:
        with open(os.path.join(label_path, file), 'r') as f:
            lines = f.readlines()
            for line in lines:
                parts = list(map(float, line.strip().split()))
                data.append([file, *parts])
                classes.add(int(parts[0]))
    df = pd.DataFrame(data, columns=['file', 'class', 'x_center', 'y_center', 'width', 'height'])
    return df, sorted(classes)

train_labels, train_classes = load_labels(train_lbl)
val_labels, val_classes = load_labels(val_lbl)
test_labels, test_classes = load_labels(test_lbl)

print("Train Labels")
print(train_labels.head())
print("\nValidation Labels")
print(val_labels.head())
print("\nValidation Labels")
print(test_labels.head())

"""in questo caso c'Ã¨ solo una classe ma la rete YOLO potrebbe riconoscere classi diverse"""

all_classes = sorted(set(train_classes + val_classes+ test_classes ))
class_names = [f'class_{i}' for i in all_classes]

print(class_names)

# Create data.yaml
data_yaml_content = f"""
train: {train_img}
val: {val_img}
test: {test_img}

nc: {len(all_classes)}  # number of classes
names: {class_names}  # class names
"""

with open(data_yaml_path, 'w') as f:
    f.write(data_yaml_content)

"""##visualizzazione"""

def visualize_sample_images(image_path, label_df, n_samples=3):
    image_files = os.listdir(image_path)[:n_samples]
    for img_file in image_files:
        img_path = os.path.join(image_path, img_file)
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        fig, ax = plt.subplots(1, 1, figsize=(10, 10))
        ax.imshow(img)
        labels = label_df[label_df['file'] == img_file]
        for _, label in labels.iterrows():
            x_center = int(label['x_center'] * img.shape[1])
            y_center = int(label['y_center'] * img.shape[0])
            width = int(label['width'] * img.shape[1])
            height = int(label['height'] * img.shape[0])
            x_min = x_center - width // 2
            y_min = y_center - height // 2

            rect = plt.Rectangle((x_min, y_min), width, height, edgecolor='red', facecolor='none', linewidth=2)
            ax.add_patch(rect)

        plt.title(f'Sample Image: {img_file}')
        plt.axis('off')
        plt.show()

visualize_sample_images(train_img, train_labels)
visualize_sample_images(val_img, val_labels)
visualize_sample_images(test_img, test_labels)

# Visualize sample detections
def visualize_detections(model, image_path, n_samples=10):
    image_files = os.listdir(image_path)[:n_samples]
    for img_file in image_files:
        img_path = os.path.join(image_path, img_file)
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = model(img_path)

        fig, ax = plt.subplots(1, 1, figsize=(10, 10))
        ax.imshow(img)

        for result in results[0].boxes:
            x_min, y_min, x_max, y_max = result.xyxy[0].tolist()
            conf = result.conf[0].item()
            rect = plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, edgecolor='red', facecolor='none', linewidth=2)
            ax.add_patch(rect)
            ax.text(x_min, y_min, f'{conf:.2f}', bbox=dict(facecolor='yellow', alpha=0.5))

        plt.title(f'Detection in: {img_file}')
        plt.axis('off')
        plt.show()

"""## YOLO11"""

import torch
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

from ultralytics import YOLO

model = YOLO('yolo11n.pt')

"""#Prova 1

in questa prima prova ho usato 50 epoche e batch da 16

##Train
"""

result=model.train(data=data_yaml_path, epochs=50, batch=16,device=device)

"""##validation"""

# Evaluate the model
metrics= model.val()
print(metrics.box.map)
# Save the trained model
model.save("/content/drive/MyDrive/dataset/best.pt")

visualize_detections(model, test_img)

print("Model training, evaluation, and sample visualization completed")

"""#Prova 2

in questo caso ho provato ad usare come optimizer Adam

##Train
"""

model2 = YOLO('yolo11n.pt')

result2=model2.train(data=data_yaml_path, epochs=50, batch=16,device=device, optimizer='Adam')

"""##validation"""

metrics2= model2.val()
print(metrics2.box.map)
# Save the trained model
model2.save("/content/drive/MyDrive/dataset/best2.pt")

visualize_detections(model2, test_img)

print("Model2 training, evaluation, and sample visualization completed")

"""# Prova3

ho deciso di aumentare le epoche anche se aumenta il rischio di overfitting dato dal ridotto contenuto di immagini
"""

model3 = YOLO('yolo11n.pt')

"""##Train"""

result3=model3.train(data=data_yaml_path, epochs=100,device=device, optimizer='Adam')

"""##Vlaidation"""

metrics3= model3.val()
print(metrics3.box.map)
# Save the trained model
model3.save("/content/drive/MyDrive/dataset/best3.pt")

visualize_detections(model3, test_img)

print("Model3 training, evaluation, and sample visualization completed")

"""#Prova4"""

model4 = YOLO('yolo11n.pt')

"""##Train"""

result4=model4.train(data=data_yaml_path, epochs=100, lr0=1E-3, device=device, optimizer='SGD')

"""##Validation"""

metrics4= model4.val()
print(metrics4.box.map)
# Save the trained model
model4.save("/content/drive/MyDrive/dataset/best4.pt")

visualize_detections(model4, test_img)

print("Model4 training, evaluation, and sample visualization completed")